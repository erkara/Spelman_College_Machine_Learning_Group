{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085d71a",
   "metadata": {},
   "source": [
    "## 1.Pytorch Basics\n",
    "## 2. Tensor Operations\n",
    "## 3. Evaluating Derivatives\n",
    "## 4. Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca9b868",
   "metadata": {},
   "source": [
    "Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration (more on that later). The name “tensor” is a generalization of concepts you already know. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. When working with neural networks, we will use tensors of various shapes and number of dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d3d19",
   "metadata": {},
   "source": [
    "## 1.Pytorch Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.,3.,6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[3,4],\n",
    "                 [9,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)\n",
    "print(A.shape)\n",
    "print(A.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad08c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A[0,1])\n",
    "print(A[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34880979",
   "metadata": {},
   "source": [
    "We have tons of methods to create special types of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b595733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=0\n",
    "print(A[0])\n",
    "print(A[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9410fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2061fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0,10, size=(4,4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497cfd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Batch, Channel, Height, Width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2451f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13169095",
   "metadata": {},
   "source": [
    "## 2. Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a0b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[3,4,7,7],\n",
    "                  [9,5,9,1],\n",
    "                  [-4,-3,5,0],\n",
    "                  [-1,-2,5,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603651ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0:2,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0cdc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.tensor([[1,1,1,1],\n",
    "                  [2,2,2,2],\n",
    "                  [3,3,3,3]])\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96bf610",
   "metadata": {},
   "source": [
    "Some unexpected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f213ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sum over the elements of the first axis, which are the rows in fact.\n",
    "B.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd34aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B[0])\n",
    "print(B[1])\n",
    "print(B[2])\n",
    "print('B[0]+B[1]+B[2] = ',B[0]+B[1]+B[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe380e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B[0].sum())\n",
    "print(B[1].sum())\n",
    "print(B[2].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e65fb1",
   "metadata": {},
   "source": [
    "Manipulating tensor with reshape, view, flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.randint(10,(3,4))\n",
    "print('Before reshape =:\\n',B)\n",
    "C = torch.reshape(B,(2,6))\n",
    "print('\\nAfter reshape:\\n', C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let the torch handle the other axis\n",
    "C = B.view(-1,4)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86379949",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d07ba4",
   "metadata": {},
   "source": [
    "One important operation includes \"torch.argmax\" and \"torch.eq\" operations. Imagine we are doing image classification with 4 classes \n",
    "\n",
    "$A = 0, B = 1 ,C = 2, D = 3$\n",
    "\n",
    "What we do, we feed many images at the same time. Let's say we feed 2 class-B and 1 class-D. Our label array is\n",
    "\n",
    "$$\\text{label} = [1,1,3]$$\n",
    "\n",
    "When we get the output from the model, it will look like;\n",
    "\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "12.2099 & 7.4075 & 1.9746,& 4.5719 \\\\\n",
    "0.4014 & 19.8903 & 9.4084 & 9.3722 \\\\\n",
    "3.3393 & 5.6968 & 8.2905 & 12.3987\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "First row is the prediction for the first image and so on. Now, in each row, we get the index of largest entry and put this in an array using **\"argmax\"** command. This will be our prediction array. In this case, it must be\n",
    "\n",
    "$$ \\text{predictions} = [0,1,3]$$ \n",
    "Then we will count how many of the predictions is right. To do so, we will first Boolen compare labels and predictions using **\"eq\"** then count the True entries using **\"sum\"**. Carefully follow the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba78fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct labels: A,B,A,C,D,A,C\n",
    "label = torch.randint(0,4,size=(1,20))\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4faaaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 10*torch.rand(20,4)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bed28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = output.argmax(dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.eq(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73602059",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_correct = torch.sum(predictions.eq(label))\n",
    "print(number_of_correct.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de518ddc",
   "metadata": {},
   "source": [
    "## 3. Evaluating Derivatives with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe6288",
   "metadata": {},
   "source": [
    "**Ex-1**\n",
    "\n",
    "Find the derivative of $f(x) = 3x^2$ at $x=1$. Note that the answer is 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79627caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.,requires_grad = True)\n",
    "y = 3*x**2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73605f",
   "metadata": {},
   "source": [
    "**Ex2**\n",
    "\n",
    "Calculate the derivative of $f(x) = \\big(x^2+ 7x + \\cos(x)\\big)^3 $ at $x=0$. Since $f'(x) = 3\\big(x^2+ 7x + \\cos(x)\\big)^2\\big(x+7-\\sin(x)\\big)$, we must have $f'(0)=21$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee6d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(0.,requires_grad = True)\n",
    "y = (x**2 + 7*x + torch.cos(x))**3\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296bb1f",
   "metadata": {},
   "source": [
    "**Ex3**\n",
    "\n",
    "Now, let's evaluate partial derivatives. $f(x,y) = x^2+y^2 + e^{x+y}\\cos(xy)$ at $x=1,y=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945628fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(1.,requires_grad = True)\n",
    "y = torch.tensor(2.,requires_grad = True)\n",
    "f = x**2 + y**2 + torch.exp(x+y)*torch.cos(x*y)\n",
    "f.backward()\n",
    "print('f_x: ',x.grad)\n",
    "print(\"f_y: \",y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f9ee8",
   "metadata": {},
   "source": [
    "## 4. Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ab173",
   "metadata": {},
   "source": [
    "Now, let's see how we do gradient decent with Pytorch. Our toy example is a simple linear regression problem. We will find the best line $$y=wx+c$$ to approximate a given set of data points $(x_i,y_i)_{i=1}^{N}$. Idea is to minimize the mean-square cost (MSE) function $$C=\\dfrac{1}{N}\\sum_{i=1}^{N}\\Big(y(x_i)-y_i\\Big)^2$$\n",
    "\n",
    "Using chain rule, we can see that $$\\dfrac{\\partial C}{\\partial w} = \\dfrac{1}{N}\\sum_{i=1}^{N}2\\Big(y(x_i)-y_i\\Big)x_i$$, $$ \\dfrac{\\partial C}{\\partial b} = \\dfrac{1}{N}\\sum_{i=1}^{N}2\\Big(y(x_i)-y_i\\Big)1$$\n",
    "Now we can go ahead and write the gradient decent for this problem. \n",
    "\n",
    "\\begin{align}\n",
    "    \\begin{bmatrix}\n",
    "           w_{n+1} \\\\\n",
    "           b_{n+1} \\\\\n",
    "     \\end{bmatrix} =\n",
    "     \\begin{bmatrix}\n",
    "           w_{n} \\\\\n",
    "           b_{n} \\\\\n",
    "      \\end{bmatrix} -\n",
    "      r\\begin{bmatrix}\n",
    "           \\dfrac{\\partial C}{\\partial w} \\\\\n",
    "          \\dfrac{\\partial C}{\\partial b} \\\\\n",
    "      \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "We will have two approches;\n",
    "\n",
    "- Implement naive graident decent with Pytorch\n",
    "- Use optimizer provided by Pytorch\n",
    "\n",
    "We can notice that Pytorch's implementation is way better in terms of error. That's why we must use the optimization tools provided in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf62b746",
   "metadata": {},
   "source": [
    "### a. Implement Naive Graident Decent with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ef19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y,y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "\n",
    "def model(w,b,x):\n",
    "    return w*x+b\n",
    "\n",
    "@torch.no_grad()\n",
    "def DisplayResults(w,b,X_test,Y_test):\n",
    "    y_preds = w * X_test + b\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(X_test,y_preds,'-b',X_test,Y_test,'ro',markersize = 2)\n",
    "    plt.legend(['predicted','real_values'])\n",
    "    plt.xlabel('x_values')\n",
    "    plt.ylabel('y_values')\n",
    "    plt.title('Linear_Regression_Model')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick w = 7 and b = 3 and some noise\n",
    "N = 300\n",
    "X = torch.rand(N)\n",
    "Y = 7*X + 3*torch.ones(N) + torch.rand(N)\n",
    "\n",
    "#train-test split\n",
    "X_train = X[0:math.ceil(N*0.8)]\n",
    "X_test = X[math.ceil(N*0.8):]\n",
    "\n",
    "Y_train = Y[0:math.ceil(N*0.8)]\n",
    "Y_test = Y[math.ceil(N*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629d76f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initilize weight and bias\n",
    "num_epochs = 400\n",
    "lr = 1e-1\n",
    "w = torch.randn(1,requires_grad=True)\n",
    "b = torch.randn(1,requires_grad=True)\n",
    "for i in range(num_epochs):\n",
    "    #(1)FORWARD PASS\n",
    "    \n",
    "    #compute the predictions\n",
    "    y_pred = model(w,b,X_train)\n",
    "    \n",
    "    #compute the loss\n",
    "    loss = MSE(Y_train,y_pred)\n",
    "    \n",
    "    #(2)BACK-PROPOGATION    \n",
    "    \n",
    "    #compute the gradients\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w.data = w.data - lr * w.grad\n",
    "        b.data = b.data - lr * b.grad\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    if i%100==0:\n",
    "        print(f'w: {w.item():0.5f} b : {b.item():0.5f} loss : {loss.item():0.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8209769",
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayResults(w,b,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4d8b6",
   "metadata": {},
   "source": [
    "### b. Implement  Graident Decent with Pytorch Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Better way of doing gradient decent. In fact, this is what we must do!\n",
    "optimizer = torch.optim.Adam([w, b], lr = 0.1)\n",
    "for i in range(num_epochs):\n",
    "    #(1)FORWARD PASS\n",
    "    \n",
    "    #compute the predictions\n",
    "    y_pred = model(w,b,X_train)\n",
    "    \n",
    "    #compute the loss\n",
    "    loss = MSE(Y_train,y_pred)\n",
    "    \n",
    "    #(2)BACK-PROPOGATION    \n",
    "    \n",
    "    #compute the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    #update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    #detach the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(f'w: {w.item():0.5f} b : {b.item():0.5f} loss : {loss.item():0.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayResults(w,b,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d90d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d06717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc6ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
